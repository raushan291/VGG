{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNTX5bJ7OM8WlqFDVwSGv8N"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"SCpONmnvjQ5a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1597057459986,"user_tz":-330,"elapsed":5183,"user":{"displayName":"RAUSHAN KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKPidrEbBhw9gVCzGQ6f3PV8AJpx25Kcnf3mxh=s64","userId":"11148087558451086823"}},"outputId":"e97a687f-ece0-4d7e-b34d-3a6990cf8a41"},"source":["import torch\n","import torch.nn as nn\n","\n","# VGG-16 consist of 13 (convolution+ReLU) and 3 (Linear layer) layers.\n","# we are dividing 13 (convolution+ReLu) layer in 5 bolocks (each block has 2, 2, 3, 3, 3 layers respectively.)\n","\n","class Vgg16(nn.Module):\n","  def __init__(self, num_classes):\n","    super(Vgg16, self).__init__()\n","\n","    self.block_1 = nn.Sequential(\n","        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(),\n","\n","        nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n","    )\n","\n","    self.block_2 = nn.Sequential(\n","        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.ReLU(),\n","\n","        nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n","    )\n","\n","    self.block_3 = nn.Sequential(\n","        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(),\n","\n","        nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n","    )\n","\n","    self.block_4 = nn.Sequential(\n","        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),\n","\n","        nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n","    )\n","\n","    self.block_5 = nn.Sequential(\n","        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),\n","\n","        nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n","    )\n","\n","    self.classifier = nn.Sequential(\n","        nn.Linear(in_features=512*7*7, out_features=4096, bias=True),\n","        nn.ReLU(inplace=True),\n","        nn.Dropout(p=0.65),\n","\n","        nn.Linear(in_features=4096, out_features=4096, bias=True),\n","        nn.ReLU(inplace=True),\n","        nn.Dropout(p=0.65),\n","\n","        nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n","    )\n","\n","  def forward(self, x):\n","    x = self.block_1(x)\n","    x = self.block_2(x)\n","    x = self.block_3(x)\n","    x = self.block_4(x)\n","    x = self.block_5(x)\n","    \n","    x = x.reshape(x.size(0), -1)\n","    \n","    x = self.classifier(x)\n","\n","    return x\n","\n","\n","def test():\n","  net=Vgg16(num_classes=10)\n","  # print(net)\n","\n","  input = torch.randn(5, 3, 227, 227)\n","  output = net(input)\n","  print(output.size())\n","  print(output)\n","\n","test()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([5, 10])\n","tensor([[ 0.0546, -0.0829,  0.1916, -0.2159, -0.3285, -0.3313, -0.0315, -0.2309,\n","         -0.6633,  0.2569],\n","        [ 0.2230,  0.4417, -0.2617,  0.1346,  0.1163,  0.0604, -0.2171, -0.0720,\n","          0.2622, -0.1226],\n","        [-0.3235, -0.6737,  0.3178,  0.1756, -0.7803,  0.2556,  0.1842,  0.0458,\n","          0.2396,  0.3762],\n","        [ 0.1002,  0.1873,  0.2532, -0.5960,  0.1629,  0.3485,  0.3076,  0.3567,\n","          0.2461,  0.1259],\n","        [ 0.1446, -0.0625,  0.4446, -0.3263, -0.1336,  0.4496,  0.1494, -0.4542,\n","          0.2188,  0.1593]], grad_fn=<AddmmBackward>)\n"],"name":"stdout"}]}]}